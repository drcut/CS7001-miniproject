import torch
import torch.nn as nn
import torch.nn.functional as F
import spconv.pytorch as spconv

width = 4096
height = 1024

# Encoder is the previous serveral layers from reuse_dis_predictor
class Encoder(nn.Module):
    def __init__(self):
        super(Encoder, self).__init__()
        self.net = spconv.SparseSequential(
            spconv.SubMConv2d(1, 64, 3, 1),
            nn.ReLU(),
            nn.BatchNorm1d(64),
            spconv.SparseMaxPool2d(2, 2, indice_key="subm0"),
            spconv.SubMConv2d(64, 64, 3, 1),
            nn.BatchNorm1d(64),
            spconv.SparseMaxPool2d(2, 2, indice_key="subm1"),
            spconv.SubMConv2d(64, 64, 3, 1),
            nn.BatchNorm1d(64),
            spconv.SparseMaxPool2d(2, 2, indice_key="subm2"),
            spconv.SubMConv2d(64, 64, 3, 1),
            nn.BatchNorm1d(64),
            spconv.SparseMaxPool2d(2, 2, indice_key="subm3"),
            spconv.SubMConv2d(64, 64, 3, 1),
            nn.BatchNorm1d(64),
            spconv.SparseMaxPool2d(2, 2, indice_key="subm4"),
            spconv.SubMConv2d(64, 64, 3, 1),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            spconv.SparseMaxPool2d(2, 2, indice_key="subm5"),
        )

    def forward(self, x_sp):
        x = self.net(x_sp)
        return x

# Decoder is the reverse version of encoder
class Decoder(nn.Module):
    def __init__(self):
        super(Decoder, self).__init__()
        self.net = spconv.SparseSequential(
            spconv.SparseInverseConv2d(64, 64, 2, indice_key="subm5"),
            nn.ReLU(),
            nn.BatchNorm1d(64),
            spconv.SparseInverseConv2d(64, 64, 2, indice_key="subm4"),
            nn.BatchNorm1d(64),
            spconv.SparseInverseConv2d(64, 64, 2, indice_key="subm3"),
            nn.BatchNorm1d(64),
            spconv.SparseInverseConv2d(64, 64, 2, indice_key="subm2"),
            nn.BatchNorm1d(64),
            spconv.SparseInverseConv2d(64, 64, 2, indice_key="subm1"),
            nn.BatchNorm1d(64),
            spconv.SparseInverseConv2d(64, 1, 2, indice_key="subm0"),
        )

    def forward(self, x):
        # x: sparse tensor generated by encoder
        x = self.net(x)
        return x

class AutoEncoder(nn.Module):
    def __init__(self):
        super(AutoEncoder, self).__init__()
        self.encoder = Encoder()
        self.decoder = Decoder()
        self.to_dense = spconv.ToDense()
    
    def encode(self, x):
        # x: must be NHWC tensor
        x_sp = spconv.SparseConvTensor.from_dense(x.reshape(-1, height, width, 1))
        x_sp = self.encoder(x_sp)
        return x_sp

    def decode(self, x_sp):
        x_sp = self.decoder(x_sp)
        x = self.to_dense(x_sp)
        # output = F.softmax(x, dim=2)
        return x

    def forward(self, x):
        raise NotImplementEderror